#include "gtest/gtest.h"
#include <fstream>
#include <kiwi/Kiwi.h>
#include <kiwi/SwTokenizer.h>
#include "common.h"

using namespace kiwi;

Kiwi& reuseKiwiInstance();

template<class Ty>
inline std::string to_string_with_fill(Ty value, char chr, size_t width = 0)
{
	std::string ret = std::to_string(value);
	if (ret.size() < width)
	{
		ret.insert(ret.begin(), width - ret.size(), chr);
	}
	return ret;
}

template<class Ty, class ATy, size_t n>
constexpr std::vector<std::pair<Ty, Ty>> toPair(const ATy(&init)[n])
{
	static_assert(n % 2 == 0, "initializer_list must have an even number of elements.");
	return std::vector<std::pair<Ty, Ty>>{ (const std::pair<Ty, Ty>*)init, (const std::pair<Ty, Ty>*)init + n / 2 };
}

TEST(KiwiSwTokenizer, Builder)
{
	using VocabTy = std::tuple<std::string, POSTag, SwTokenFlag, float>;

	SwTokenizerConfig config;
	config.specialTokens[config.unk] = u8"[UNK]";
	config.specialTokens[config.cls] = u8"[CLS]";
	SwTokenizerBuilder builder{ reuseKiwiInstance(), config };

	std::initializer_list<VocabTy> vocabs = {
		VocabTy{ config.specialTokens[config.unk], POSTag::unknown, SwTokenFlag::special, 0}, // 0
		VocabTy{ u8"í•˜", POSTag::vv, SwTokenFlag::none, -3.33 }, // 1
		VocabTy{ u8".", POSTag::unknown, SwTokenFlag::none, -3.34 }, // 2
		VocabTy{ u8"ì–´", POSTag::ep, SwTokenFlag::none, -3.89 }, // 3
		VocabTy{ u8"ì´", POSTag::vv, SwTokenFlag::none, -4.06 }, // 4
		VocabTy{ u8"á†«", POSTag::ep, SwTokenFlag::none, -4.09 }, // 5
		VocabTy{ u8"ì—ˆ", POSTag::ep, SwTokenFlag::none, -4.15 }, // 6
		VocabTy{ u8"ì„", POSTag::jks, SwTokenFlag::none, -4.79 }, // 7
		VocabTy{ u8"ì‚¬ëŒ", POSTag::unknown, SwTokenFlag::subword, -5.00 }, // 8
		VocabTy{ u8"ë§", POSTag::unknown, SwTokenFlag::none, -5.10 }, // 9
		VocabTy{ u8"ìƒê°", POSTag::unknown, SwTokenFlag::none, -5.20 }, // 10
		VocabTy{ u8"ì˜›", POSTag::unknown, SwTokenFlag::none, -5.30 }, // 11
		VocabTy{ u8"", POSTag::unknown, SwTokenFlag::glue, -6.0 }, // 12
		VocabTy{ config.specialTokens[config.cls], POSTag::unknown, SwTokenFlag::special, 0}, // 13
	};
	for (auto& t : vocabs)
	{
		builder.addToken(std::get<0>(t), std::get<1>(t), std::get<2>(t), std::get<3>(t));
	}
	auto tokenizer = builder.build();
	EXPECT_EQ(tokenizer.size(), vocabs.size());

	std::string inp, reconstructed;
	std::vector<uint32_t> res;
	std::vector<std::pair<uint32_t, uint32_t>> offsets;

	{
		inp = u8"ë§í•œ ì˜›ì‚¬ëŒì„ ìƒê°í–ˆì–´..";
		offsets.clear();
		res = tokenizer.encode(inp, &offsets);
		EXPECT_EQ(res, std::vector<uint32_t>({ 9, 1, 5, 11, 8, 7, 10, 1, 6, 3, 2, 2 }));
		EXPECT_EQ(res.size(), offsets.size());
		EXPECT_EQ(offsets, toPair<uint32_t>({ 0, 3, 3, 6, 3, 6, 7, 10, 10, 16, 16, 19, 20, 26, 26, 29, 26, 29, 29, 32, 32, 33, 33, 34 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, inp);
	}

	{
		inp = u8"ì˜› ìƒê°";
		offsets.clear();
		res = tokenizer.encode(inp, &offsets);
		EXPECT_EQ(res, std::vector<uint32_t>({ 11, 10 }));
		EXPECT_EQ(res.size(), offsets.size());
		EXPECT_EQ(offsets, toPair<uint32_t>({ 0, 3, 4, 10 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, inp);
	}

	{
		inp = u8"ì˜›ìƒê°";
		offsets.clear();
		res = tokenizer.encode(inp, &offsets);
		EXPECT_EQ(res, std::vector<uint32_t>({ 11, 12, 10 }));
		EXPECT_EQ(res.size(), offsets.size());
		EXPECT_EQ(offsets, toPair<uint32_t>({ 0, 3, 3, 3, 3, 9 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, inp);
	}

	{
		inp = u8"[CLS] ì˜ ëª¨ë¥´ëŠ” ë‹¨ì–´";
		offsets.clear();
		res = tokenizer.encode(inp, &offsets);
		EXPECT_EQ(res, std::vector<uint32_t>({ 13, 0, 0, 0 }));
		EXPECT_EQ(res.size(), offsets.size());
		EXPECT_EQ(offsets, toPair<uint32_t>({ 0, 5, 6, 9, 10, 19, 20, 26 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, u8"[CLS] [UNK] [UNK] [UNK]");
	}

	{
		std::ofstream ofs{ "test_tokenizer.json" };
		tokenizer.save(ofs);
	}

	{
		std::ifstream ifs{ "test_tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
	}

	{
		inp = u8"ë§í•œ ì˜›ì‚¬ëŒì„ ìƒê°í–ˆì–´..";
		res = tokenizer.encode(inp);
		EXPECT_EQ(res, std::vector<uint32_t>({ 9, 1, 5, 11, 8, 7, 10, 1, 6, 3, 2, 2 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, inp);
	}

	{
		inp = u8"ì˜› ìƒê°";
		res = tokenizer.encode(inp);
		EXPECT_EQ(res, std::vector<uint32_t>({ 11, 10 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, inp);
	}

	{
		inp = u8"ì˜›ìƒê°";
		res = tokenizer.encode(inp);
		EXPECT_EQ(res, std::vector<uint32_t>({ 11, 12, 10 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, inp);
	}

	{
		inp = u8"[CLS] ì˜ ëª¨ë¥´ëŠ” ë‹¨ì–´";
		res = tokenizer.encode(inp);
		EXPECT_EQ(res, std::vector<uint32_t>({ 13, 0, 0, 0 }));

		reconstructed = tokenizer.decode(res);
		EXPECT_EQ(reconstructed, u8"[CLS] [UNK] [UNK] [UNK]");
	}
}

TEST(KiwiSwTokenizer, BasicEncodeAndDecode)
{
	SwTokenizer tokenizer;
	{
		std::ifstream ifs{ "test/written.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
	}

	for (auto c : { 
		u8"",
		u8"í•œêµ­ì–´ì— íŠ¹í™”ëœ í† í¬ë‚˜ì´ì €ì…ë‹ˆë‹¤.", 
		u8"ê°ì‚¬íˆ ë¨¹ê² ìŠµë‹ˆë‹¹!",
		u8"ë…¸ë˜ì§„ ì†í†±ì„ ë´¤ë˜ê±¸ìš”.",
		u8"ì œì„ìŠ¤ì›¹ìš°ì£¼ì²œì²´ë§ì›ê²½",
		u8"ê·¸ë§Œí•´ì—¬~",
		//u8"ê³µë¶€ë„ ì‹œí‚¬ ë§Œí¼ ì‹œì¼°ëŠ”ë° ë¯¸ì³ë²„ë¦¬ë‹¤ë‹ˆ",
	})
	{
		std::vector<std::pair<uint32_t, uint32_t>> offsets;
		auto encoded = tokenizer.encode(c, &offsets);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, c);
	}
}

TEST(KiwiSwTokenizer, EncodeFromAlreadyTokenized)
{
	SwTokenizer tokenizer;
	{
		std::ifstream ifs{ "test/written.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
	}

	for (auto c : {
		u8"",
		u8"í•œêµ­ì–´ì— íŠ¹í™”ëœ í† í¬ë‚˜ì´ì €ì…ë‹ˆë‹¤.",
		u8"ê°ì‚¬íˆ ë¨¹ê² ìŠµë‹ˆë‹¹!",
		u8"ë…¸ë˜ì§„ ì†í†±ì„ ë´¤ë˜ê±¸ìš”.",
		u8"ì œì„ìŠ¤ì›¹ìš°ì£¼ì²œì²´ë§ì›ê²½",
		u8"ê·¸ë§Œí•´ì—¬~",
	})
	{
		auto result = tokenizer.getKiwi()->analyze(c, Match::allWithNormalizing | Match::zCoda).first;
		std::vector<std::pair<std::u16string, POSTag>> tokens;
		std::vector<std::tuple<std::u16string, POSTag, bool>> tokensWithSpaceness;
		for (auto& t : result)
		{
			tokens.emplace_back(t.str, t.tag);
			bool hasSpacePrefix = &t == result.data() || ((&t)[-1].position + (&t)[-1].length < t.position);
			tokensWithSpaceness.emplace_back(t.str, t.tag, hasSpacePrefix);
		}
		auto encoded = tokenizer.encode(tokens);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, c);
		
		auto encodedUsingSpaceness = tokenizer.encode(tokensWithSpaceness);
		auto decodedUsingSpaceness = tokenizer.decode(encodedUsingSpaceness);
		EXPECT_EQ(decodedUsingSpaceness, c);
	}

	for (auto c : {
		u8"ì œì„ìŠ¤ì›¹ ìš°ì£¼ì²œì²´ë§ì›ê²½",
	})
	{
		auto result = tokenizer.getKiwi()->analyze(c, Match::allWithNormalizing | Match::zCoda).first;
		std::vector<std::tuple<std::u16string, POSTag, bool>> tokensWithSpaceness;
		for (auto& t : result)
		{
			bool hasSpacePrefix = &t == result.data() || ((&t)[-1].position + (&t)[-1].length < t.position);
			tokensWithSpaceness.emplace_back(t.str, t.tag, hasSpacePrefix);
		}
		auto encodedUsingSpaceness = tokenizer.encode(tokensWithSpaceness);
		auto decodedUsingSpaceness = tokenizer.decode(encodedUsingSpaceness);
		EXPECT_EQ(decodedUsingSpaceness, c);
	}
}

TEST(KiwiSwTokenizer, WholeWordUnk)
{
	SwTokenizer tokenizer;
	{
		std::ifstream ifs{ "test/written.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
	}

	auto c = u8"í™”íì˜ ì£¼ì¸ê³µì€ 110ì—¬ ë…„ ì „ì˜ ì—¬ë¥˜ ì§ì—… ì†Œì„¤ê°€ 'íˆêµ¬ì¹˜ ì´ì¹˜ìš”æ¨‹å£ä¸€è‘‰'ì´ë‹¤.";
	{
		tokenizer.setWholeWordUnk(false);
		auto encoded = tokenizer.encode(c);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, u8"í™”íì˜ ì£¼ì¸ê³µì€ 110ì—¬ ë…„ ì „ì˜ ì—¬ë¥˜ ì§ì—… ì†Œì„¤ê°€'íˆêµ¬ì¹˜ ì´ì¹˜ìš” [UNK]å£ä¸€è‘‰'ì´ë‹¤.");
	}

	{
		tokenizer.setWholeWordUnk(true);
		auto encoded = tokenizer.encode(c);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, u8"í™”íì˜ ì£¼ì¸ê³µì€ 110ì—¬ ë…„ ì „ì˜ ì—¬ë¥˜ ì§ì—… ì†Œì„¤ê°€'íˆêµ¬ì¹˜ [UNK]'ì´ë‹¤.");
	}
}

TEST(KiwiSwTokenizer, FallbackHangul)
{
	auto c = u8"ë¶„ì„ì´ ì–´ë ¤ìš´ í•œê¸€ì—ëŠ” ëš®ë·‡ê´— ë“±ì´ ìˆë‹¤.";
	SwTokenizer tokenizer;
	{
		std::ifstream ifs{ "test/written.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
		auto encoded = tokenizer.encode(c);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, u8"ë¶„ì„ì´ ì–´ë ¤ìš´ í•œê¸€ì—ëŠ” [UNK] ë“±ì´ ìˆë‹¤.");
	}

	{
		std::ifstream ifs{ "test/written.fallback_hangul.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
		auto encoded = tokenizer.encode(c);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, u8"ë¶„ì„ì´ ì–´ë ¤ìš´ í•œê¸€ì—ëŠ” ëš®ë·‡ê´— ë“±ì´ ìˆë‹¤.");
	}
}

TEST(KiwiSwTokenizer, FallbackByte)
{
	auto c = u8"ë¶„ì„ì´ ì–´ë ¤ìš´ ìœ ë‹ˆì½”ë“œì—ëŠ” ğŸ’¯Î·ğŸ’¢ğŸ’¥ ë“±ì´ ìˆë‹¤.";
	SwTokenizer tokenizer;
	{
		std::ifstream ifs{ "test/written.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
		auto encoded = tokenizer.encode(c);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, u8"ë¶„ì„ì´ ì–´ë ¤ìš´ ìœ ë‹ˆì½”ë“œì—ëŠ” [UNK] ë“±ì´ ìˆë‹¤.");
	}

	{
		std::ifstream ifs{ "test/written.fallback_byte.tokenizer.json" };
		tokenizer = SwTokenizer::load(reuseKiwiInstance(), ifs);
		auto encoded = tokenizer.encode(c);
		auto decoded = tokenizer.decode(encoded);
		EXPECT_EQ(decoded, u8"ë¶„ì„ì´ ì–´ë ¤ìš´ ìœ ë‹ˆì½”ë“œì—ëŠ” ğŸ’¯Î·ğŸ’¢ğŸ’¥ ë“±ì´ ìˆë‹¤.");
	}
}

